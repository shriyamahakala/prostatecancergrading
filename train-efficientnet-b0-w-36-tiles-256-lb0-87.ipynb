{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"DEBUG = False #changed from true to false","metadata":{"execution":{"iopub.status.busy":"2022-01-25T02:28:37.162319Z","iopub.execute_input":"2022-01-25T02:28:37.162572Z","iopub.status.idle":"2022-01-25T02:28:37.166767Z","shell.execute_reply.started":"2022-01-25T02:28:37.162545Z","shell.execute_reply":"2022-01-25T02:28:37.165838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install git+https://github.com/ildoonet/pytorch-gradual-warmup-lr.git\n#!pip install pytorch_lightning","metadata":{"execution":{"iopub.status.busy":"2022-01-25T02:28:37.172655Z","iopub.execute_input":"2022-01-25T02:28:37.172921Z","iopub.status.idle":"2022-01-25T02:28:46.185188Z","shell.execute_reply.started":"2022-01-25T02:28:37.172896Z","shell.execute_reply":"2022-01-25T02:28:46.18411Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import os\nimport sys\nsys.path = [\n    '../input/efficientnet-pytorch/EfficientNet-PyTorch/EfficientNet-PyTorch-master',\n] + sys.path","metadata":{"execution":{"iopub.status.busy":"2022-01-24T00:22:40.420772Z","iopub.execute_input":"2022-01-24T00:22:40.421106Z","iopub.status.idle":"2022-01-24T00:22:40.426167Z","shell.execute_reply.started":"2022-01-24T00:22:40.421067Z","shell.execute_reply":"2022-01-24T00:22:40.425305Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import time\nimport skimage.io\nimport numpy as np\nimport pandas as pd\nimport cv2\nimport PIL.Image\nimport torch\nimport torchvision.models as models\n\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.utils.data.sampler import SubsetRandomSampler, RandomSampler, SequentialSampler\nfrom warmup_scheduler import GradualWarmupScheduler\nfrom efficientnet_pytorch import model as enet\nimport albumentations\nfrom sklearn.model_selection import StratifiedKFold\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import cohen_kappa_score\nfrom tqdm import tqdm_notebook as tqdm\n\n\n\nfrom torch.autograd import Variable\nfrom torch.nn.parameter import Parameter\n\nfrom collections import OrderedDict\n\nimport math\n\nfrom torch.utils import model_zoo\n\n#import pytorch_lightning as pl\n\n\n\n\n#from layer import AdaptiveConcatPool2d, Flatten, GeM, SEBlock\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-01-24T00:22:40.428056Z","iopub.execute_input":"2022-01-24T00:22:40.428719Z","iopub.status.idle":"2022-01-24T00:22:43.291424Z","shell.execute_reply.started":"2022-01-24T00:22:40.428677Z","shell.execute_reply":"2022-01-24T00:22:43.290571Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"markdown","source":"# Config","metadata":{}},{"cell_type":"code","source":"data_dir = '../input/prostate-cancer-grade-assessment'\ndf_train = pd.read_csv(os.path.join(data_dir, 'train.csv'))\nimage_folder = os.path.join(data_dir, 'train_images')\n\ntorch.cuda.empty_cache()\n\nkernel_type = 'how_to_train_effnet_b0_to_get_LB_0.86'\n\nenet_type = 'efficientnet-b2'\nfold = 0\ntile_size = 192  #256\nimage_size = 192 #256\nn_tiles = 64 #36\nbatch_size = 2\nnum_workers = 4\nout_dim = 5\ninit_lr = 3e-4\nwarmup_factor = 10\n\nwarmup_epo = 1\nn_epochs = 1 if DEBUG else 5\ndf_train = df_train.sample(100).reset_index(drop=True) if DEBUG else df_train\n\ndevice = torch.device('cuda')\n\nprint(image_folder)\n","metadata":{"execution":{"iopub.status.busy":"2022-01-24T00:22:43.294456Z","iopub.execute_input":"2022-01-24T00:22:43.294831Z","iopub.status.idle":"2022-01-24T00:22:43.328689Z","shell.execute_reply.started":"2022-01-24T00:22:43.294796Z","shell.execute_reply":"2022-01-24T00:22:43.327844Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Folds","metadata":{}},{"cell_type":"code","source":"skf = StratifiedKFold(5, shuffle=True, random_state=42) \ndf_train['fold'] = -1\n\nfor i, (train_idx, valid_idx) in enumerate(skf.split(df_train, df_train['isup_grade'])):\n    df_train.loc[valid_idx, 'fold'] = i\n    \ndf_train.head()\n\n\n\n#i=0\n#=0\n#print(skip_ids[1])\n\n#while j < len(skip_ids):\n  #      df_train.drop[skip_ids[j]]\n    #df_train = df_train.drop(~df_train[\"image_id\"].isin(skip_ids))\n\n\n","metadata":{"execution":{"iopub.status.busy":"2022-01-24T00:22:43.33065Z","iopub.execute_input":"2022-01-24T00:22:43.331023Z","iopub.status.idle":"2022-01-24T00:22:43.36398Z","shell.execute_reply.started":"2022-01-24T00:22:43.330985Z","shell.execute_reply":"2022-01-24T00:22:43.363202Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class AdaptiveConcatPool2d(nn.Module):\n    def __init__(self, sz=None):\n        super().__init__()\n        sz = sz or (1, 1)\n        self.ap = nn.AdaptiveAvgPool2d(sz)\n        self.mp = nn.AdaptiveMaxPool2d(sz)\n\n    def forward(self, x):\n        return torch.cat([self.mp(x), self.ap(x)], 1)\nclass Flatten(nn.Module):\n    def forward(self, input):\n        return input.view(input.size(0), -1)\n\ndef gem(x, p=3, eps=1e-6):\n    return F.avg_pool2d(x.clamp(min=eps).pow(p), (x.size(-2), x.size(-1))).pow(1.0 / p)\n\nclass GeM(nn.Module):\n    def __init__(self, p=3, eps=1e-6):\n        super(GeM, self).__init__()\n        self.p = Parameter(torch.ones(1) * p)\n        self.eps = eps\n\n    def forward(self, x):\n        return gem(x, p=self.p, eps=self.eps)\n\n    def __repr__(self):\n        return (\n            self.__class__.__name__\n            + f\"(p={self.p.data.tolist()[0]:.4f}, eps={str(self.eps)})\"\n        )\nclass SEBlock(nn.Module):\n    def __init__(self, in_ch, r=8):\n        super(SEBlock, self).__init__()\n\n        self.linear_1 = nn.Linear(in_ch, in_ch // r)\n        self.linear_2 = nn.Linear(in_ch // r, in_ch)\n\n    def forward(self, x):\n        input_x = x\n\n        x = F.relu(self.linear_1(x), inplace=True)\n        x = self.linear_2(x)\n        x = torch.sigmoid(x)\n\n        x = input_x * x\n\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-01-24T00:22:43.365313Z","iopub.execute_input":"2022-01-24T00:22:43.365748Z","iopub.status.idle":"2022-01-24T00:22:43.384189Z","shell.execute_reply.started":"2022-01-24T00:22:43.365709Z","shell.execute_reply":"2022-01-24T00:22:43.383189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"pretrained_settings = {\"se_resnext50_32x4d\": {\n        \"imagenet\": {\n            \"url\": \"http://data.lip6.fr/cadene/pretrainedmodels/se_resnext50_32x4d-a260b3a4.pth\",\n            \"input_space\": \"RGB\",\n            \"input_size\": [3, 224, 224],\n            \"input_range\": [0, 1],\n            \"mean\": [0.485, 0.456, 0.406],\n            \"std\": [0.229, 0.224, 0.225],\n            \"num_classes\": 1000,\n        }}}\n\npretrained_model = {\n    'efficientnet-b1': '../input/efficientnet-pytorch/efficientnet-b1-dbc7070a.pth',\n    'efficientnet-b0': '../input/efficientnet-pytorch/efficientnet-b0-08094119.pth',\n    'efficientnet-b2': '../input/efficientnet-pytorch/efficientnet-b2-27687264.pth',\n    'efficientnet-b3': \"../input/efficientnet-pytorch/efficientnet-b3-c8376fa2.pth\"\n}\n\n#model_ft = models.vgg16(pretrained=True)","metadata":{"execution":{"iopub.status.busy":"2022-01-24T00:22:43.385968Z","iopub.execute_input":"2022-01-24T00:22:43.386793Z","iopub.status.idle":"2022-01-24T00:22:43.394433Z","shell.execute_reply.started":"2022-01-24T00:22:43.38675Z","shell.execute_reply":"2022-01-24T00:22:43.393465Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class enetv2(nn.Module):\n#class enetv2(pl.LightningModule):\n    def __init__(self, backbone, out_dim):\n        super(enetv2, self).__init__()\n        self.enet = enet.EfficientNet.from_name(backbone)\n        self.enet.load_state_dict(torch.load(pretrained_model[backbone]))\n\n        self.myfc = nn.Linear(self.enet._fc.in_features, out_dim)\n        self.enet._fc = nn.Identity() #Switches from batch normalization to group normalization. Normalization layers standardize inputs and outputs\n\n    def extract(self, x):\n        return self.enet(x)\n\n    def forward(self, x):\n        x = self.extract(x)\n        x = self.myfc(x) #normalizes feature \n        return x\n    #def configure_optimizers(self):\n    #    optimizer = optim.Adam(model.parameters(), lr=init_lr)\n    #   return optimizer\n    \nclass EfficientNetB3(nn.Module):\n    def __init__(self, out_dim):\n        super(EfficientNetB3, self).__init__()\n        self.enet = enet.EfficientNet.from_name('efficientnet-b3')\n        self.enet.load_state_dict(torch.load('../input/efficientnet-pytorch/efficientnet-b3-c8376fa2.pth'))\n                  \n        self.myfc = nn.Linear(self.enet._fc.in_features, out_dim)\n        self.enet._fc = nn.Identity() #Switches from batch normalization to group normalization. Normalization layers standardize inputs and outputs\n\n\n    def extract(self, x):\n        return self.enet(x)\n\n    def forward(self, x):\n        x = self.extract(x)\n        x = self.myfc(x) #normalizes feature \n        return x\n    \n\n   \nclass CustomEfficientNet(nn.Module):\n    def __init__(\n        self,\n        base=\"efficientnet-b0\",\n        pool_type=\"gem\",\n        in_ch=3,\n        out_ch=1,\n        pretrained=False,\n    ):\n        super(CustomEfficientNet, self).__init__()\n        assert base in {\n            \"efficientnet-b0\",\n            \"efficientnet-b1\",\n            \"efficientnet-b2\",\n            \"efficientnet-b3\",\n            \"efficientnet-b4\",\n        }\n        assert pool_type in {\"concat\", \"avg\", \"gem\"}\n\n        self.base = base\n        self.in_ch = in_ch\n        self.out_ch = out_ch\n        self.pretrained = pretrained\n\n        if pretrained:\n            self.net = enet.EfficientNet.from_pretrained(base)\n        else:\n            self.net = enet.EfficientNet.from_name(base)\n\n        out_shape = self.net._fc.in_features\n        if pool_type == \"concat\":\n            self.net._avg_pooling = AdaptiveConcatPool2d()\n            out_shape = out_shape * 2\n        elif pool_type == \"gem\":\n            self.net._avg_pooling = GeM()\n            out_shape = out_shape\n        self.net._fc = nn.Sequential(\n            Flatten(), SEBlock(out_shape), nn.Dropout(), nn.Linear(out_shape, out_ch)\n        )\n\n        if in_ch != 3:\n            old_in_ch = 3\n            old_conv = self.net._conv_stem\n\n            # Make new weight\n            weight = old_conv.weight\n            new_weight = torch.cat([weight] * (self.in_ch // old_in_ch), dim=1)\n\n            # Make new conv\n            new_conv = nn.Conv2d(\n                in_channels=self.in_ch,\n                out_channels=old_conv.out_channels,\n                kernel_size=old_conv.kernel_size,\n                stride=old_conv.stride,\n                padding=old_conv.padding,\n                bias=old_conv.bias,\n            )\n\n            self.net._conv_stem = new_conv\n            self.net._conv_stem.weight = nn.Parameter(new_weight)\n\n    def forward(self, x):\n        x = self.net(x)\n        return x\n","metadata":{"execution":{"iopub.status.busy":"2022-01-24T00:22:43.396148Z","iopub.execute_input":"2022-01-24T00:22:43.396592Z","iopub.status.idle":"2022-01-24T00:22:43.423303Z","shell.execute_reply.started":"2022-01-24T00:22:43.396557Z","shell.execute_reply":"2022-01-24T00:22:43.422355Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class SEModule(nn.Module):\n    def __init__(self, channels, reduction):\n        super(SEModule, self).__init__()\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.fc1 = nn.Conv2d(channels, channels // reduction, kernel_size=1, padding=0)\n        self.relu = nn.ReLU(inplace=True)\n        self.fc2 = nn.Conv2d(channels // reduction, channels, kernel_size=1, padding=0)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x):\n        module_input = x\n        x = self.avg_pool(x)\n        x = self.fc1(x)\n        x = self.relu(x)\n        x = self.fc2(x)\n        x = self.sigmoid(x)\n        return module_input * x\n    \nclass Bottleneck(nn.Module):\n    \"\"\"\n    Base class for bottlenecks that implements `forward()` method.\n    \"\"\"\n\n    def forward(self, x):\n        residual = x\n\n        out = self.conv1(x)\n        out = self.bn1(out)\n        out = self.relu(out)\n\n        out = self.conv2(out)\n        out = self.bn2(out)\n        out = self.relu(out)\n\n        out = self.conv3(out)\n        out = self.bn3(out)\n\n        if self.downsample is not None:\n            residual = self.downsample(x)\n\n        out = self.se_module(out) + residual\n        out = self.relu(out)\n\n        return out\n    \ndef initialize_pretrained_model(model, num_classes, settings):\n    assert num_classes == settings[\"num_classes\"], \"num_classes should be {}, but is {}\".format(\n        settings[\"num_classes\"], num_classes\n    )\n    model.load_state_dict(model_zoo.load_url(settings[\"url\"]))\n    model.input_space = settings[\"input_space\"]\n    model.input_size = settings[\"input_size\"]\n    model.input_range = settings[\"input_range\"]\n    model.mean = settings[\"mean\"]\n    model.std = settings[\"std\"]\n    \nclass SEResNeXtBottleneck(Bottleneck):\n    \"\"\"\n    ResNeXt bottleneck type C with a Squeeze-and-Excitation module.\n    \"\"\"\n\n    expansion = 4\n\n    def __init__(\n        self, inplanes, planes, groups, reduction, stride=1, downsample=None, base_width=4\n    ):\n        super(SEResNeXtBottleneck, self).__init__()\n        width = math.floor(planes * (base_width / 64)) * groups\n        self.conv1 = nn.Conv2d(inplanes, width, kernel_size=1, bias=False, stride=1)\n        self.bn1 = nn.BatchNorm2d(width)\n        self.conv2 = nn.Conv2d(\n            width, width, kernel_size=3, stride=stride, padding=1, groups=groups, bias=False\n        )\n        self.bn2 = nn.BatchNorm2d(width)\n        self.conv3 = nn.Conv2d(width, planes * 4, kernel_size=1, bias=False)\n        self.bn3 = nn.BatchNorm2d(planes * 4)\n        self.relu = nn.ReLU(inplace=True)\n        self.se_module = SEModule(planes * 4, reduction=reduction)\n        self.downsample = downsample\n        self.stride = stride\n    \nclass SENet(nn.Module):\n    def __init__(\n        self,\n        block,\n        layers,\n        groups,\n        reduction,\n        dropout_p=0.2,\n        inplanes=128,\n        input_3x3=True,\n        downsample_kernel_size=3,\n        downsample_padding=1,\n        num_classes=1000,\n    ):\n        super(SENet, self).__init__()\n        self.inplanes = inplanes\n        if input_3x3:\n            layer0_modules = [\n                (\"conv1\", nn.Conv2d(3, 64, 3, stride=2, padding=1, bias=False)),\n                (\"bn1\", nn.BatchNorm2d(64)),\n                (\"relu1\", nn.ReLU(inplace=True)),\n                (\"conv2\", nn.Conv2d(64, 64, 3, stride=1, padding=1, bias=False)),\n                (\"bn2\", nn.BatchNorm2d(64)),\n                (\"relu2\", nn.ReLU(inplace=True)),\n                (\"conv3\", nn.Conv2d(64, inplanes, 3, stride=1, padding=1, bias=False)),\n                (\"bn3\", nn.BatchNorm2d(inplanes)),\n                (\"relu3\", nn.ReLU(inplace=True)),\n            ]\n        else:\n            layer0_modules = [\n                (\"conv1\", nn.Conv2d(3, inplanes, kernel_size=7, stride=2, padding=3, bias=False)),\n                (\"bn1\", nn.BatchNorm2d(inplanes)),\n                (\"relu1\", nn.ReLU(inplace=True)),\n            ]\n        # To preserve compatibility with Caffe weights `ceil_mode=True`\n        # is used instead of `padding=1`.\n        layer0_modules.append((\"pool\", nn.MaxPool2d(3, stride=2, ceil_mode=True)))\n        self.layer0 = nn.Sequential(OrderedDict(layer0_modules))\n        self.layer1 = self._make_layer(\n            block,\n            planes=64,\n            blocks=layers[0],\n            groups=groups,\n            reduction=reduction,\n            downsample_kernel_size=1,\n            downsample_padding=0,\n        )\n        self.layer2 = self._make_layer(\n            block,\n            planes=128,\n            blocks=layers[1],\n            stride=2,\n            groups=groups,\n            reduction=reduction,\n            downsample_kernel_size=downsample_kernel_size,\n            downsample_padding=downsample_padding,\n        )\n        self.layer3 = self._make_layer(\n            block,\n            planes=256,\n            blocks=layers[2],\n            stride=2,\n            groups=groups,\n            reduction=reduction,\n            downsample_kernel_size=downsample_kernel_size,\n            downsample_padding=downsample_padding,\n        )\n        self.layer4 = self._make_layer(\n            block,\n            planes=512,\n            blocks=layers[3],\n            stride=2,\n            groups=groups,\n            reduction=reduction,\n            downsample_kernel_size=downsample_kernel_size,\n            downsample_padding=downsample_padding,\n        )\n        self.avg_pool = nn.AvgPool2d(7, stride=1)\n        self.dropout = nn.Dropout(dropout_p) if dropout_p is not None else None\n        self.last_linear = nn.Linear(512 * block.expansion, num_classes)\n\n    def _make_layer(\n        self,\n        block,\n        planes,\n        blocks,\n        groups,\n        reduction,\n        stride=1,\n        downsample_kernel_size=1,\n        downsample_padding=0,\n    ):\n        downsample = None\n        if stride != 1 or self.inplanes != planes * block.expansion:\n            downsample = nn.Sequential(\n                nn.Conv2d(\n                    self.inplanes,\n                    planes * block.expansion,\n                    kernel_size=downsample_kernel_size,\n                    stride=stride,\n                    padding=downsample_padding,\n                    bias=False,\n                ),\n                nn.BatchNorm2d(planes * block.expansion),\n            )\n\n        layers = []\n        layers.append(block(self.inplanes, planes, groups, reduction, stride, downsample))\n        self.inplanes = planes * block.expansion\n        for i in range(1, blocks):\n            layers.append(block(self.inplanes, planes, groups, reduction))\n\n        return nn.Sequential(*layers)\n\n    def features(self, x):\n        x = self.layer0(x)\n        x = self.layer1(x)\n        x = self.layer2(x)\n        x = self.layer3(x)\n        x = self.layer4(x)\n        return x\n\n    def logits(self, x):\n        x = self.avg_pool(x)\n        if self.dropout is not None:\n            x = self.dropout(x)\n        x = x.view(x.size(0), -1)\n        x = self.last_linear(x)\n        return x\n\n    def forward(self, x):\n        x = self.features(x)\n        x = self.logits(x)\n        return x\n\ndef se_resnext50_32x4d(num_classes=1000, pretrained=\"imagenet\"):\n    model = SENet(\n        SEResNeXtBottleneck,\n        [3, 4, 6, 3],\n        groups=32,\n        reduction=16,\n        dropout_p=None,\n        inplanes=64,\n        input_3x3=False,\n        downsample_kernel_size=1,\n        downsample_padding=0,\n        num_classes=num_classes,\n    )\n    if pretrained is not None:\n        settings = pretrained_settings[\"se_resnext50_32x4d\"][pretrained]\n        initialize_pretrained_model(model, num_classes, settings)\n    return model\n\nclass CustomSEResNeXt(nn.Module):\n    \"\"\"\n    Refer from https://github.com/okotaku/kaggle_rsna2019_3rd_solution/blob/master/src/model.py\n    \"\"\"\n\n    def __init__(\n        self,\n        model_name=\"se_resnext50_32x4d\",\n        in_ch=3,\n        out_ch=1,\n        pool_type=\"concat\",\n        pretrained=False,\n    ):\n        assert model_name in {\"se_resnext50_32x4d\"}\n        assert pool_type in {\"concat\", \"avg\", \"gem\"}\n        assert in_ch % 3 == 0\n        super().__init__()\n\n        self.net = se_resnext50_32x4d(pretrained=\"imagenet\" if pretrained else None)\n\n        out_shape = 2048\n        if pool_type == \"concat\":\n            self.net.avg_pool = AdaptiveConcatPool2d()\n            out_shape = out_shape * 2\n        elif pool_type == \"avg\":\n            self.net.avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n            out_shape = out_shape\n        elif pool_type == \"gem\":\n            self.net.avg_pool = GeM()\n            out_shape = out_shape\n        self.net.last_linear = nn.Sequential(\n            Flatten(), SEBlock(out_shape), nn.Dropout(), nn.Linear(out_shape, out_ch)\n        )\n\n    def forward(self, x):\n        x = self.net(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2022-01-24T00:22:43.424991Z","iopub.execute_input":"2022-01-24T00:22:43.42539Z","iopub.status.idle":"2022-01-24T00:22:43.487107Z","shell.execute_reply.started":"2022-01-24T00:22:43.425356Z","shell.execute_reply":"2022-01-24T00:22:43.48637Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Dataset","metadata":{}},{"cell_type":"code","source":"def get_tiles(img, mode=0): #does tiling stuff \n        result = []\n        h, w, c = img.shape\n        pad_h = (tile_size - h % tile_size) % tile_size + ((tile_size * mode) // 2)\n        pad_w = (tile_size - w % tile_size) % tile_size + ((tile_size * mode) // 2)\n\n        img2 = np.pad(img,[[pad_h // 2, pad_h - pad_h // 2], [pad_w // 2,pad_w - pad_w//2], [0,0]], constant_values=255)\n        img3 = img2.reshape(\n            img2.shape[0] // tile_size,\n            tile_size,\n            img2.shape[1] // tile_size,\n            tile_size,\n            3\n        )\n\n        img3 = img3.transpose(0,2,1,3,4).reshape(-1, tile_size, tile_size,3)\n        n_tiles_with_info = (img3.reshape(img3.shape[0],-1).sum(1) < tile_size ** 2 * 3 * 255).sum()\n        if len(img3) < n_tiles:\n            img3 = np.pad(img3,[[0,n_tiles-len(img3)],[0,0],[0,0],[0,0]], constant_values=255)\n        idxs = np.argsort(img3.reshape(img3.shape[0],-1).sum(-1))[:n_tiles]\n        img3 = img3[idxs]\n        for i in range(len(img3)):\n            result.append({'img':img3[i], 'idx':i})\n        return result, n_tiles_with_info >= n_tiles\n \nclass PANDADataset(Dataset):\n    def __init__(self,\n                 df,\n                 image_size,\n                 n_tiles=n_tiles,\n                 tile_mode=0,\n                 rand=False,\n                 transform=None,\n                ):\n\n        self.df = df.reset_index(drop=True)\n        self.image_size = image_size\n        self.n_tiles = n_tiles\n        self.tile_mode = tile_mode\n        self.rand = rand\n        self.transform = transform\n\n    def __len__(self):\n        return self.df.shape[0]\n\n    def __getitem__(self, index):\n        row = self.df.iloc[index]\n        img_id = row.image_id\n        \n        tiff_file = os.path.join(image_folder, f'{img_id}.tiff')\n        image = skimage.io.MultiImage(tiff_file)[1]\n        tiles, OK = get_tiles(image, self.tile_mode)\n\n        if self.rand:\n            idxes = np.random.choice(list(range(self.n_tiles)), self.n_tiles, replace=False)\n        else:\n            idxes = list(range(self.n_tiles))\n\n        n_row_tiles = int(np.sqrt(self.n_tiles))\n        images = np.zeros((image_size * n_row_tiles, image_size * n_row_tiles, 3))\n        for h in range(n_row_tiles):\n            for w in range(n_row_tiles):\n                i = h * n_row_tiles + w\n    \n                if len(tiles) > idxes[i]:\n                    this_img = tiles[idxes[i]]['img']\n                else:\n                    this_img = np.ones((self.image_size, self.image_size, 3)).astype(np.uint8) * 255\n                this_img = 255 - this_img\n                if self.transform is not None:\n                    this_img = self.transform(image=this_img)['image']\n                h1 = h * image_size\n                w1 = w * image_size\n                images[h1:h1+image_size, w1:w1+image_size] = this_img\n\n        if self.transform is not None:\n            images = self.transform(image=images)['image']\n        images = images.astype(np.float32)\n        images /= 255\n        images = images.transpose(2, 0, 1)\n\n        label = np.zeros(5).astype(np.float32)\n        label[:row.isup_grade] = 1.\n        return torch.tensor(images), torch.tensor(label)\n\n#tiff_file = os.path.join(image_folder, '0005f7aaab2800f6170c399693a96917.tiff')\n#image = skimage.io.MultiImage(tiff_file)[1]\n\n#fig, ax = plt.subplots(2, 2, figsize=(20, 25))\n\n#ax[0][0].imshow(image)\n\n#ax[1][0].imshow(get_tiles(image,0))","metadata":{"execution":{"iopub.status.busy":"2022-01-24T00:22:43.489123Z","iopub.execute_input":"2022-01-24T00:22:43.489431Z","iopub.status.idle":"2022-01-24T00:22:43.518762Z","shell.execute_reply.started":"2022-01-24T00:22:43.489402Z","shell.execute_reply":"2022-01-24T00:22:43.517722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Augmentations","metadata":{}},{"cell_type":"code","source":"transforms_train = albumentations.Compose([\n    albumentations.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.05, rotate_limit=10, border_mode=cv2.BORDER_CONSTANT, p=0.5,value=(255,255,255)),\n            albumentations.OneOf([\n                albumentations.Flip(p=0.5),\n                albumentations.RandomRotate90(p=0.5),\n            ], p=0.3\n    #albumentations.Transpose(p=0.5),\n    #albumentations.VerticalFlip(p=0.5),\n    #albumentations.HorizontalFlip(p=0.5),\n            )])\n    \ntransforms_val = albumentations.Compose([])","metadata":{"execution":{"iopub.status.busy":"2022-01-24T00:22:43.520407Z","iopub.execute_input":"2022-01-24T00:22:43.52111Z","iopub.status.idle":"2022-01-24T00:22:43.530117Z","shell.execute_reply.started":"2022-01-24T00:22:43.521072Z","shell.execute_reply":"2022-01-24T00:22:43.529275Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dataset_show = PANDADataset(df_train, image_size, n_tiles, 0, transform=transforms_train) #modifies the panda dataset\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 20,10\nfor i in range(2):\n    f, axarr = plt.subplots(1,5)\n    for p in range(5):\n        idx = np.random.randint(0, len(dataset_show))\n        img, label = dataset_show[idx]\n        axarr[p].imshow(1. - img.transpose(0, 1).transpose(1,2).squeeze())\n        axarr[p].set_title(str(sum(label)))\n","metadata":{"execution":{"iopub.status.busy":"2022-01-24T00:22:43.531747Z","iopub.execute_input":"2022-01-24T00:22:43.532258Z","iopub.status.idle":"2022-01-24T00:22:53.650922Z","shell.execute_reply.started":"2022-01-24T00:22:43.532218Z","shell.execute_reply":"2022-01-24T00:22:53.650062Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loss","metadata":{}},{"cell_type":"code","source":"criterion = nn.BCEWithLogitsLoss() #this is just what determines like how good the model is working\n#use OUSM instead","metadata":{"execution":{"iopub.status.busy":"2022-01-24T00:22:53.652569Z","iopub.execute_input":"2022-01-24T00:22:53.65291Z","iopub.status.idle":"2022-01-24T00:22:53.657473Z","shell.execute_reply.started":"2022-01-24T00:22:53.652874Z","shell.execute_reply":"2022-01-24T00:22:53.656547Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Train & Val","metadata":{}},{"cell_type":"code","source":"def train_epoch(loader, optimizer):\n\n    model.train()\n    train_loss = []\n    bar = tqdm(loader)\n    for (data, target) in bar:\n        \n        data, target = data.to(device), target.to(device)\n        loss_func = criterion\n        optimizer.zero_grad()\n        logits = model(data)\n        loss = loss_func(logits, target)\n        loss.backward()\n        optimizer.step()\n\n        loss_np = loss.detach().cpu().numpy()\n        train_loss.append(loss_np)\n        smooth_loss = sum(train_loss[-100:]) / min(len(train_loss), 100)\n        bar.set_description('loss: %.5f, smth: %.5f' % (loss_np, smooth_loss))\n    return train_loss\n\n\ndef val_epoch(loader, get_output=False):\n\n    model.eval()\n    val_loss = []\n    LOGITS = []\n    PREDS = []\n    TARGETS = []\n\n    with torch.no_grad():\n        for (data, target) in tqdm(loader):\n            data, target = data.to(device), target.to(device)\n            logits = model(data)\n\n            loss = criterion(logits, target)\n\n            pred = logits.sigmoid().sum(1).detach().round()\n            LOGITS.append(logits)\n            PREDS.append(pred)\n            TARGETS.append(target.sum(1))\n\n            val_loss.append(loss.detach().cpu().numpy())\n        val_loss = np.mean(val_loss)\n\n    LOGITS = torch.cat(LOGITS).cpu().numpy()\n    PREDS = torch.cat(PREDS).cpu().numpy()\n    TARGETS = torch.cat(TARGETS).cpu().numpy()\n    acc = (PREDS == TARGETS).mean() * 100.\n    \n    qwk = cohen_kappa_score(PREDS, TARGETS, weights='quadratic')\n    qwk_k = cohen_kappa_score(PREDS[df_valid['data_provider'] == 'karolinska'], df_valid[df_valid['data_provider'] == 'karolinska'].isup_grade.values, weights='quadratic')\n    qwk_r = cohen_kappa_score(PREDS[df_valid['data_provider'] == 'radboud'], df_valid[df_valid['data_provider'] == 'radboud'].isup_grade.values, weights='quadratic')\n    print('qwk', qwk, 'qwk_k', qwk_k, 'qwk_r', qwk_r)\n\n    if get_output:\n        return LOGITS\n    else:\n        return val_loss, acc, qwk\n\n    ","metadata":{"execution":{"iopub.status.busy":"2022-01-24T00:22:53.659361Z","iopub.execute_input":"2022-01-24T00:22:53.659746Z","iopub.status.idle":"2022-01-24T00:22:53.683808Z","shell.execute_reply.started":"2022-01-24T00:22:53.659711Z","shell.execute_reply":"2022-01-24T00:22:53.683035Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Create Dataloader & Model & Optimizer","metadata":{}},{"cell_type":"markdown","source":"# Run Training","metadata":{}},{"cell_type":"code","source":"train_idx = np.where((df_train['fold'] != fold))[0]\nvalid_idx = np.where((df_train['fold'] == fold))[0]\n\n\ndf_this  = df_train.loc[train_idx ]\ndf_valid = df_train.loc[valid_idx]\n\nskip_df = pd.read_csv(\"../input/panda-analysis/PANDA_Suspicious_Slides.csv\")\nskip_ids = list(skip_df[\"image_id\"])\ndf_this = df_this[~df_this[\"image_id\"].isin(skip_ids)]\ndf_valid = df_valid[~df_valid[\"image_id\"].isin(skip_ids)]\n\n\ndataset_train = PANDADataset(df_this , image_size, n_tiles, transform=transforms_train)\ndataset_valid = PANDADataset(df_valid, image_size, n_tiles, transform=transforms_val)\n\ntrain_loader = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, sampler=RandomSampler(dataset_train), num_workers=num_workers)\nvalid_loader = torch.utils.data.DataLoader(dataset_valid, batch_size=batch_size, sampler=SequentialSampler(dataset_valid), num_workers=num_workers)\n\nin_ch = 3\nmodel = enetv2(enet_type, out_dim=out_dim)\n#CustomSEResNeXt(in_ch=3, out_ch=out_dim, pool_type=\"gem\", pretrained=False)\n#\n#CustomEfficientNet(base=\"efficientnet-b0\", pool_type=\"gem\", out_ch=out_dim)\n\n#\n#EfficientNetB3(out_dim=out_dim)\n\n\n\n\noptimizer = optim.Adam(model.parameters(), lr=init_lr/warmup_factor)\nscheduler_cosine = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, n_epochs-warmup_epo)\nscheduler = GradualWarmupScheduler(optimizer, multiplier=warmup_factor, total_epoch=warmup_epo, after_scheduler=scheduler_cosine)\n\ncheckpoint = torch.load('../input/checkpoint3/model5epochs(1).pth')\n\nmodel.load_state_dict(checkpoint['model_state_dict'])\n\nmodel = model.to(device)\n\noptimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n\ntrain_loss = checkpoint['loss']\n\n\nprint(len(dataset_train), len(dataset_valid))","metadata":{"execution":{"iopub.status.busy":"2022-01-24T00:23:55.030964Z","iopub.execute_input":"2022-01-24T00:23:55.031294Z","iopub.status.idle":"2022-01-24T00:23:55.461431Z","shell.execute_reply.started":"2022-01-24T00:23:55.031263Z","shell.execute_reply":"2022-01-24T00:23:55.460521Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nqwk_max = 0.\nbest_file = f'{kernel_type}_best_fold{fold}.pth'\nfor epoch in range(1, n_epochs+1):\n    print(time.ctime(), 'Epoch:', epoch)\n    scheduler.step(epoch-1)\n\n    train_loss = train_epoch(train_loader, optimizer)\n    val_loss, acc, qwk = val_epoch(valid_loader)\n\n    content = time.ctime() + ' ' + f'Epoch {epoch}, lr: {optimizer.param_groups[0][\"lr\"]:.7f}, train loss: {np.mean(train_loss):.5f}, val loss: {np.mean(val_loss):.5f}, acc: {(acc):.5f}, qwk: {(qwk):.5f}'\n    print(content)\n    with open(f'log_{kernel_type}.txt', 'a') as appender:\n        appender.write(content + '\\n')\n\n    if qwk > qwk_max:\n        print('score2 ({:.6f} --> {:.6f}).  Saving model ...'.format(qwk_max, qwk))\n        torch.save(model.state_dict(), best_file)\n        qwk_max = qwk\n\ntorch.save(model.state_dict(), os.path.join(f'{kernel_type}_final_fold{fold}.pth'))\ntorch.save({\n            'model_state_dict': model.state_dict(),\n            'optimizer_state_dict': optimizer.state_dict(),\n            'loss': train_loss,\n            }, os.path.join(f'model5epochs.pth'))","metadata":{"execution":{"iopub.status.busy":"2022-01-24T00:23:57.888918Z","iopub.execute_input":"2022-01-24T00:23:57.889252Z","iopub.status.idle":"2022-01-24T00:24:07.986992Z","shell.execute_reply.started":"2022-01-24T00:23:57.889222Z","shell.execute_reply":"2022-01-24T00:24:07.985082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}